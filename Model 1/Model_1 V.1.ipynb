{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "0LJuMhZ0dG1L",
        "outputId": "37342a7a-de41-4435-9482-95ea1726065f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.13.1)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"d:/Semester 5/CO543 Image Processing/3-Mini Project/e20-co543-Low-Light-Image-Enhancement/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, BatchNormalization, ReLU, UpSampling2D\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# 1. Histogram Equalization\n",
        "def histogram_equalization(img):\n",
        "    # Convert the image to HSV (Hue, Saturation, Value)\n",
        "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Apply histogram equalization to the V (Value) channel (intensity)\n",
        "    hsv_img[..., 2] = cv2.equalizeHist(hsv_img[..., 2])\n",
        "\n",
        "    # Convert back to BGR color space\n",
        "    eq_color_img = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    return eq_color_img\n",
        "\n",
        "# 2. Gamma Correction\n",
        "def gamma_correction(img, gamma):\n",
        "    # Apply gamma correction\n",
        "    invGamma = 1.0 / gamma\n",
        "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in range(256)]).astype(\"uint8\")\n",
        "    gamma_corrected = cv2.LUT(img, table)\n",
        "    return gamma_corrected\n",
        "\n",
        "# 3. Deep Learning-Based Enhancement (CNN Model)\n",
        "def create_deep_learning_model(input_shape=(500, 500, 3)):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolution layers for feature extraction\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # Upsampling layers to enhance image resolution\n",
        "    model.add(UpSampling2D(size=(2, 2)))\n",
        "    model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))  # Output layer with 3 channels for color image\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "def increase_contrast(img, factor=2):\n",
        "    # Convert the image to float32 to avoid clipping\n",
        "    img_float = img.astype(np.float32)\n",
        "\n",
        "    # Increase the contrast by multiplying the pixel values by a factor\n",
        "    img_float = img_float * factor\n",
        "\n",
        "    # Clip the values to be within the valid range [0, 255]\n",
        "    img_float = np.clip(img_float, 0, 255)\n",
        "\n",
        "    # Convert back to uint8\n",
        "    contrast_img = img_float.astype(np.uint8)\n",
        "\n",
        "    return contrast_img\n",
        "\n",
        "# Load your low-light image\n",
        "good_img = cv2.imread('2.png')  # Replace with the path to your image\n",
        "ori_img = cv2.imread('2L.png')  # Replace with the path to your image\n",
        "\n",
        "# #image with high conrast\n",
        "high_contrast_img = increase_contrast(ori_img)\n",
        "\n",
        "# Apply Histogram Equalization\n",
        "hist_eq_img = histogram_equalization(ori_img)\n",
        "\n",
        "# Apply Gamma Correction\n",
        "gamma_img = gamma_correction(high_contrast_img, gamma=2)  # You can change the gamma value for desired brightness\n",
        "\n",
        "# Show the results\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Original Image\")\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(cv2.cvtColor(good_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Good Image\")\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(cv2.cvtColor(hist_eq_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Histogram Equalized Image\")\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(cv2.cvtColor(gamma_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Gamma Corrected Image\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Now, we will prepare the image for deep learning enhancement\n",
        "# Resize image to 500x500\n",
        "img_resized = cv2.resize(ori_img, (500, 500))\n",
        "\n",
        "# Create and train the deep learning model\n",
        "model = create_deep_learning_model()\n",
        "\n",
        "# Note: Training the model would require a dataset of low-light and corresponding high-quality images.\n",
        "# For demonstration, we assume the model is pre-trained or fine-tuned.\n",
        "\n",
        "# For this example, we'll simulate a \"fake\" training by enhancing the image.\n",
        "# Normally, you'd use a dataset with both low-light and high-quality images to train the model.\n",
        "\n",
        "enhanced_img = model.predict(np.expand_dims(np.float32(img_resized) / 255.0, axis=0))\n",
        "\n",
        "# Display the enhanced image from the deep learning model\n",
        "plt.imshow(enhanced_img[0])  # Assuming the model outputs an image in the range [0, 1]\n",
        "plt.title(\"Deep Learning Enhanced Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R60BdSeGlTIR",
        "outputId": "a3421ece-f01c-4db4-8f1f-45fac617eb4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PSNR: 27.200367642400252 dB\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def calculate_psnr(original, enhanced):\n",
        "    # Resize images to the same shape (e.g., 256x256 or 512x512)\n",
        "    size = (256, 256)  # You can change the size to any desired resolution\n",
        "    original_resized = cv2.resize(original, size)\n",
        "    enhanced_resized = cv2.resize(enhanced, size)\n",
        "\n",
        "    mse = np.mean((original_resized - enhanced_resized) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100  # No noise, perfect similarity\n",
        "\n",
        "    psnr = 20 * np.log10(255.0 / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "# Example of how to call the function:\n",
        "psnr_value = calculate_psnr(img, hist_eq_img)\n",
        "print(f\"PSNR: {psnr_value} dB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "yd2JlGiplCMh",
        "outputId": "b9bcc937-2de0-4d3b-e762-d91a3d5fc34e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-08762d21167c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Visualize and evaluate the enhancement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mvisualize_improvement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist_eq_img\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming model output is in range [0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-08762d21167c>\u001b[0m in \u001b[0;36mvisualize_improvement\u001b[0;34m(original, enhanced)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Calculate PSNR and SSIM for comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpsnr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mssim_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"PSNR: {psnr_value} dB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-08762d21167c>\u001b[0m in \u001b[0;36mcalculate_ssim\u001b[0;34m(original, enhanced)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Method to calculate SSIM (Structural Similarity Index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mssim_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mssim_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skimage/metrics/_structural_similarity.py\u001b[0m in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;34m'win_size exceeds image extent. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;34m'Either ensure that your images are '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels."
          ]
        }
      ],
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "import math\n",
        "\n",
        "# Method to calculate PSNR (Peak Signal-to-Noise Ratio)\n",
        "def calculate_psnr(original, enhanced):\n",
        "    mse = np.mean((original - enhanced) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100  # No noise, perfect similarity\n",
        "    max_pixel = 255.0  # For 8-bit image\n",
        "    psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "# Method to calculate SSIM (Structural Similarity Index)\n",
        "def calculate_ssim(original, enhanced):\n",
        "    ssim_value = ssim(original, enhanced, multichannel=True)\n",
        "    return ssim_value\n",
        "\n",
        "# Method to visualize the improvement using a graph\n",
        "def visualize_improvement(original, enhanced):\n",
        "    # Calculate PSNR and SSIM for comparison\n",
        "    psnr_value = calculate_psnr(original, enhanced)\n",
        "    ssim_value = calculate_ssim(original, enhanced)\n",
        "\n",
        "    print(f\"PSNR: {psnr_value} dB\")\n",
        "    print(f\"SSIM: {ssim_value}\")\n",
        "\n",
        "    # Plot the original and enhanced images side by side\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Original (Low-light Image)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Enhanced Image\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Enhanced Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Show PSNR and SSIM on the graph\n",
        "    plt.figtext(0.5, 0.01, f'PSNR: {psnr_value:.2f} dB, SSIM: {ssim_value:.3f}', ha='center', va='center', fontsize=12, color='black')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example of using these methods after enhancement\n",
        "# Apply Histogram Equalization and Gamma Correction\n",
        "hist_eq_img = histogram_equalization(img)\n",
        "# gamma_img = gamma_correction(img, gamma=1.5)\n",
        "\n",
        "# Assuming the deep learning model has already been trained or pre-loaded\n",
        "# We'll use the model to enhance the image\n",
        "enhanced_img = model.predict(np.expand_dims(np.float32(img_resized) / 255.0, axis=0))\n",
        "\n",
        "# Visualize and evaluate the enhancement\n",
        "visualize_improvement(img, enhanced_img[0])  # Assuming model output is in range [0, 1]\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

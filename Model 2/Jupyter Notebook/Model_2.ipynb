{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbHSscgdVNnl",
        "outputId": "dca00a54-5b23-4fdb-8038-72ed89c1c1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python numpy scipy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial import distance\n",
        "from scipy.ndimage.filters import convolve\n",
        "from scipy.sparse import diags, csr_matrix\n",
        "from scipy.sparse.linalg import spsolve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHJtei0gW42s",
        "outputId": "f994e26a-93ff-4080-d918-51100798e21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f2d4de94e4db>:8: DeprecationWarning: Please import `convolve` from the `scipy.ndimage` namespace; the `scipy.ndimage.filters` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  from scipy.ndimage.filters import convolve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sparse_neighbor(p: int, n: int, m: int):\n",
        "    \"\"\"Returns a dictionary of 4-neighbors of `p` in a sparse matrix.\"\"\"\n",
        "    i, j = p // m, p % m\n",
        "    d = {}\n",
        "    if i - 1 >= 0:\n",
        "        d[(i - 1) * m + j] = (i - 1, j, 0)\n",
        "    if i + 1 < n:\n",
        "        d[(i + 1) * m + j] = (i + 1, j, 0)\n",
        "    if j - 1 >= 0:\n",
        "        d[i * m + j - 1] = (i, j - 1, 1)\n",
        "    if j + 1 < m:\n",
        "        d[i * m + j + 1] = (i, j + 1, 1)\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "WDwI_1FvYf_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_spacial_affinity_kernel(spatial_sigma: float, size: int = 15):\n",
        "    kernel = np.zeros((size, size))\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            kernel[i, j] = np.exp(-0.5 * (distance.euclidean((i, j), (size // 2, size // 2)) ** 2) / (spatial_sigma ** 2))\n",
        "    return kernel\n",
        "\n",
        "\n",
        "def compute_smoothness_weights(L, x, kernel, eps=1e-3):\n",
        "    Lp = cv2.Sobel(L, cv2.CV_64F, int(x == 1), int(x == 0), ksize=1)\n",
        "    T = convolve(np.ones_like(L), kernel, mode='constant')\n",
        "    T = T / (np.abs(convolve(Lp, kernel, mode='constant')) + eps)\n",
        "    return T / (np.abs(Lp) + eps)\n",
        "\n",
        "\n",
        "def refine_illumination_map_linear(L, gamma, lambda_, kernel, eps=1e-3):\n",
        "    wx = compute_smoothness_weights(L, x=1, kernel=kernel, eps=eps)\n",
        "    wy = compute_smoothness_weights(L, x=0, kernel=kernel, eps=eps)\n",
        "\n",
        "    n, m = L.shape\n",
        "    L_1d = L.copy().flatten()\n",
        "\n",
        "    row, column, data = [], [], []\n",
        "    for p in range(n * m):\n",
        "        diag = 0\n",
        "        for q, (k, l, x) in get_sparse_neighbor(p, n, m).items():\n",
        "            weight = wx[k, l] if x else wy[k, l]\n",
        "            row.append(p)\n",
        "            column.append(q)\n",
        "            data.append(-weight)\n",
        "            diag += weight\n",
        "        row.append(p)\n",
        "        column.append(p)\n",
        "        data.append(diag)\n",
        "    F = csr_matrix((data, (row, column)), shape=(n * m, n * m))\n",
        "\n",
        "    Id = diags([np.ones(n * m)], [0])\n",
        "    A = Id + lambda_ * F\n",
        "    L_refined = spsolve(csr_matrix(A), L_1d, permc_spec=None, use_umfpack=True).reshape((n, m))\n",
        "\n",
        "    return np.clip(L_refined, eps, 1) ** gamma\n",
        "\n",
        "\n",
        "def correct_underexposure(im, gamma, lambda_, kernel, eps=1e-3):\n",
        "    L = np.max(im, axis=-1)\n",
        "    L_refined = refine_illumination_map_linear(L, gamma, lambda_, kernel, eps)\n",
        "    L_refined_3d = np.repeat(L_refined[..., None], 3, axis=-1)\n",
        "    return im / L_refined_3d\n",
        "\n",
        "\n",
        "def enhance_image_exposure(im, gamma, lambda_, dual=True, sigma=3, bc=1, bs=1, be=1, eps=1e-3):\n",
        "    kernel = create_spacial_affinity_kernel(sigma)\n",
        "    im_normalized = im.astype(float) / 255.\n",
        "    under_corrected = correct_underexposure(im_normalized, gamma, lambda_, kernel, eps)\n",
        "\n",
        "    if dual:\n",
        "        inv_im_normalized = 1 - im_normalized\n",
        "        over_corrected = 1 - correct_underexposure(inv_im_normalized, gamma, lambda_, kernel, eps)\n",
        "        merge_mertens = cv2.createMergeMertens(bc, bs, be)\n",
        "        images = [np.clip(x * 255, 0, 255).astype(\"uint8\") for x in [im_normalized, under_corrected, over_corrected]]\n",
        "        im_corrected = merge_mertens.process(images)\n",
        "    else:\n",
        "        im_corrected = under_corrected\n",
        "\n",
        "    return np.clip(im_corrected * 255, 0, 255).astype(\"uint8\")\n"
      ],
      "metadata": {
        "id": "q3LbUI2sYi-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images(args):\n",
        "    imdir = args.folder\n",
        "    if not os.path.exists(imdir):\n",
        "        os.makedirs(imdir)\n",
        "\n",
        "    ext = ['png', 'jpg', 'bmp']\n",
        "    files = []\n",
        "    [files.extend(glob.glob(imdir + '*.' + e)) for e in ext]\n",
        "    images = [cv2.imread(file) for file in files]\n",
        "\n",
        "    directory = os.path.join(imdir, \"/content/enhanced\")\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    for i, image in tqdm(enumerate(images), desc=\"Enhancing images\"):\n",
        "        enhanced_image = enhance_image_exposure(image, args.gamma, args.lambda_, not args.lime,\n",
        "                                                sigma=args.sigma, bc=args.bc, bs=args.bs, be=args.be, eps=args.eps)\n",
        "        filename = os.path.basename(files[i])\n",
        "        # name, ext = os.path.splitext(filename)\n",
        "        # method = \"LIME\" if args.lime else \"DUAL\"\n",
        "        # corrected_name = f\"{name}_{method}_g{args.gamma}_l{args.lambda_}{ext}\"\n",
        "        cv2.imwrite(os.path.join(directory, filename), enhanced_image)\n"
      ],
      "metadata": {
        "id": "557nGA9rYmkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = argparse.Namespace(\n",
        "    folder=\"/content/low/\",\n",
        "    gamma=0.6,\n",
        "    lambda_=0.15,\n",
        "    lime=False,\n",
        "    sigma=3,\n",
        "    bc=1,\n",
        "    bs=1,\n",
        "    be=1,\n",
        "    eps=1e-3\n",
        ")\n",
        "\n",
        "process_images(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QlKzxOAYqUE",
        "outputId": "7bccbd13-f304-40cc-f4e4-65385fedf9bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Enhancing images: 15it [02:24,  9.65s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Displaying the output images\n"
      ],
      "metadata": {
        "id": "jHStrHDeatGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tLgARz6SasZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "    \"\"\"Load an image and convert it to RGB format for correct display in Matplotlib.\"\"\"\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Image not found: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    image = cv2.imread(image_path)  # Read image\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "    return image"
      ],
      "metadata": {
        "id": "59MbgNaZbZKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(input_path, enhanced_path, high_path):\n",
        "    \"\"\"Display input and enhanced images side by side.\"\"\"\n",
        "    input_image = load_image(input_path)\n",
        "    enhanced_image = load_image(enhanced_path)\n",
        "    high_image = load_image(high_path)\n",
        "\n",
        "    if input_image is None or enhanced_image is None or high_image is None:\n",
        "        return\n",
        "\n",
        "    # Create a side-by-side plot\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    ax[0].imshow(input_image)\n",
        "    ax[0].set_title(\"Low Light Image\")\n",
        "    ax[0].axis(\"off\")\n",
        "\n",
        "    ax[1].imshow(enhanced_image)\n",
        "    ax[1].set_title(\"Enhanced Image\")\n",
        "    ax[1].axis(\"off\")\n",
        "\n",
        "    ax[2].imshow(high_image)\n",
        "    ax[2].set_title(\"Ground Truth\")\n",
        "    ax[2].axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "IMfjsiS6bb37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_display_images(input_folder, output_folder, high_folder):\n",
        "    \"\"\"Find input images in input_folder, locate their enhanced versions in output_folder, and display them.\"\"\"\n",
        "\n",
        "    ext = ['png', 'jpg', 'bmp']\n",
        "    input_files = []\n",
        "    [input_files.extend(glob.glob(os.path.join(input_folder, f'*.{e}'))) for e in ext]\n",
        "\n",
        "    if not input_files:\n",
        "        print(\"No images found in the input folder.\")\n",
        "        return\n",
        "\n",
        "    for input_file in input_files:\n",
        "        filename = os.path.basename(input_file)\n",
        "\n",
        "        # Look for the enhanced image in the output folder\n",
        "        enhanced_file = os.path.join(output_folder, filename)\n",
        "\n",
        "        high_file = os.path.join(high_folder, filename)\n",
        "\n",
        "        if os.path.exists(enhanced_file) and os.path.exists(high_file):\n",
        "            display_images(input_file, enhanced_file, high_file)\n",
        "        else:\n",
        "            print(f\"Enhanced image or high-quality image not found for {filename}\")\n"
      ],
      "metadata": {
        "id": "yIoVhOTxbfPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_and_display_images(input_folder=\"/content/low/\", output_folder=\"/content/enhanced/\", high_folder=\"/content/high/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UaouX4fbiE6",
        "outputId": "9e915483-b6e1-422d-a445-d1e17c8ba520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced image or high-quality image not found for 14.png\n",
            "Enhanced image or high-quality image not found for 7.png\n",
            "Enhanced image or high-quality image not found for 11.png\n",
            "Enhanced image or high-quality image not found for 2.png\n",
            "Enhanced image or high-quality image not found for 4.png\n",
            "Enhanced image or high-quality image not found for 1.png\n",
            "Enhanced image or high-quality image not found for 5.png\n",
            "Enhanced image or high-quality image not found for 6.png\n",
            "Enhanced image or high-quality image not found for 15.png\n",
            "Enhanced image or high-quality image not found for 8.png\n",
            "Enhanced image or high-quality image not found for 10.png\n",
            "Enhanced image or high-quality image not found for 9.png\n",
            "Enhanced image or high-quality image not found for 13.png\n",
            "Enhanced image or high-quality image not found for 3.png\n",
            "Enhanced image or high-quality image not found for 12.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Evaluation Techniques"
      ],
      "metadata": {
        "id": "6alR2ttXmKi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE : Mean Square Error\n",
        "Calculating the MSE of the High light image wuth the enhanced image"
      ],
      "metadata": {
        "id": "Y8VaUvYdmQji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy scipy tqdm pandas scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxKZAEx3mOTq",
        "outputId": "56609906-8583-4ad7-825c-92fd612a6df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim"
      ],
      "metadata": {
        "id": "mdsbe0r9mjCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSNR : Peak Signal to Noise Ratio"
      ],
      "metadata": {
        "id": "rnFhen2anA_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute PSNR\n",
        "def calculate_psnr(ref, img):\n",
        "    \"\"\"\n",
        "    Calculate the Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
        "\n",
        "    Parameters:\n",
        "        ref: The first image as a NumPy array.\n",
        "        img: The second image as a NumPy array.\n",
        "\n",
        "    Returns:\n",
        "        psnr: The PSNR value in decibels (dB).\n",
        "    \"\"\"\n",
        "    mse = np.mean((ref - img) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100  # Perfect match\n",
        "    max_pixel = 255.0\n",
        "    return 10 * np.log10((max_pixel ** 2) / mse)"
      ],
      "metadata": {
        "id": "B4-P2_P2m9uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SSIM : structural similarity index measure"
      ],
      "metadata": {
        "id": "7HZ9UsFqnE8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute SSIM\n",
        "def calculate_ssim(ref, img):\n",
        "    \"\"\"\n",
        "    Calculate the Structural Similarity Index (SSIM) between two images.\n",
        "\n",
        "    Parameters:\n",
        "        ref: The first image as a NumPy array.\n",
        "        img: The second image as a NumPy array.\n",
        "\n",
        "    Returns:\n",
        "        ssim_value: The SSIM value (ranges from -1 to 1).\n",
        "    \"\"\"\n",
        "    return ssim(ref, img, channel_axis=-1)"
      ],
      "metadata": {
        "id": "5zzJncKKnHpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Evaluate All Images in a Folder"
      ],
      "metadata": {
        "id": "h5AnfMCLnTbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_images(low_folder, enhanced_folder, high_folder):\n",
        "    \"\"\"Evaluate image quality metrics for all images in a folder and compute average results.\"\"\"\n",
        "\n",
        "    ext = ['png', 'jpg', 'bmp']\n",
        "    low_images = []\n",
        "    [low_images.extend(glob.glob(os.path.join(low_folder, f'*.{e}'))) for e in ext]\n",
        "\n",
        "    if not low_images:\n",
        "        print(\"No images found in the low-light folder.\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for low_file in low_images:\n",
        "        filename = os.path.basename(low_file)\n",
        "\n",
        "        # Find corresponding enhanced image\n",
        "        enhanced_file = os.path.join(enhanced_folder, filename)  # Adjust pattern if needed\n",
        "        # Find corresponding high-quality (ground truth) image\n",
        "        high_file = os.path.join(high_folder, filename)\n",
        "\n",
        "        if os.path.exists(enhanced_file) and os.path.exists(high_file):\n",
        "            # Load images\n",
        "            enhanced_img = cv2.imread(enhanced_file)\n",
        "            high_img = cv2.imread(high_file)\n",
        "\n",
        "            # Compute quality metrics\n",
        "            psnr_value = calculate_psnr(high_img, enhanced_img)\n",
        "            ssim_value = calculate_ssim(high_img, enhanced_img)\n",
        "\n",
        "            # Store results\n",
        "            results.append({\"Image\": filename, \"PSNR (dB)\": psnr_value, \"SSIM\": ssim_value})\n",
        "        else:\n",
        "            print(f\"Matching image not found for {filename}\")\n",
        "\n",
        "    # Convert results to a DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Compute the average values\n",
        "    avg_psnr = df[\"PSNR (dB)\"].mean()\n",
        "    avg_ssim = df[\"SSIM\"].mean()\n",
        "\n",
        "    print(\"\\nðŸ“Š **Evaluation Results:**\")\n",
        "    print(df)\n",
        "    print(\"\\nðŸ“Œ **Overall Average Metrics:**\")\n",
        "    print(f\"ðŸ”¹ Average PSNR: {avg_psnr:.4f} dB\")\n",
        "    print(f\"ðŸ”¹ Average SSIM: {avg_ssim:.4f}\")\n"
      ],
      "metadata": {
        "id": "kWXUx9MXnPga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_images(low_folder=\"/content/low/\", enhanced_folder=\"/content/enhanced/\", high_folder=\"/content/high/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysxpSsXgnac7",
        "outputId": "8b09e833-2eb9-44a1-db4c-f1e57e2205d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š **Evaluation Results:**\n",
            "     Image  PSNR (dB)      SSIM\n",
            "0   14.png  27.809406  0.469826\n",
            "1    7.png  28.142979  0.633399\n",
            "2   11.png  27.527465  0.336018\n",
            "3    2.png  27.567716  0.557659\n",
            "4    4.png  28.619063  0.297663\n",
            "5    1.png  27.653034  0.634395\n",
            "6    5.png  27.466599  0.552484\n",
            "7    6.png  27.502728  0.535939\n",
            "8   15.png  28.827468  0.523558\n",
            "9    8.png  30.300109  0.746125\n",
            "10  10.png  27.813502  0.546906\n",
            "11   9.png  28.813358  0.543278\n",
            "12  13.png  27.675230  0.589216\n",
            "13   3.png  28.628661  0.315303\n",
            "14  12.png  27.515978  0.500856\n",
            "\n",
            "ðŸ“Œ **Overall Average Metrics:**\n",
            "ðŸ”¹ Average PSNR: 28.1242 dB\n",
            "ðŸ”¹ Average SSIM: 0.5188\n"
          ]
        }
      ]
    }
  ]
}